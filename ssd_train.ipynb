{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# custom functions\n",
    "from model import SSD\n",
    "from dataloader import ObjectDataset, collate_fn\n",
    "from utils import Encoder, make_dirs, BoxesGen\n",
    "from utils import SSDAugmentation, Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# check cuda availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"background\", \"bicycle\", \"car\", \"motorcycle\", \"bus\"] \n",
    "colors = [None, (164, 80, 133), (39, 129, 113), (83, 122, 114), (99, 81, 172)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoc(modellib, train_loader, epochs, writer, loss_fn, optimizer, scheduler):\n",
    "    train_loss_l = []\n",
    "    train_acc_l = []\n",
    "    for epoch in range(first_epoch, epochs):\n",
    "        modellib.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        corrects = 0\n",
    "        num_iter_per_epoch = len(train_loader)\n",
    "        progress_bar = tqdm(train_loader)\n",
    "        for i, (img, _, _, grd_box, grd_lbl) in enumerate(progress_bar):\n",
    "            cnt = grd_lbl.shape[0]\n",
    "            img = img.cuda()\n",
    "            grd_box = grd_box.cuda()\n",
    "            grd_lbl = grd_lbl.cuda()\n",
    "            modellib.eval()\n",
    "            pred_box, pred_lbl = modellib(img)\n",
    "            pred_box, pred_lbl = pred_box.float(), pred_lbl.float()\n",
    "            # print(\"grd_box:\", grd_box.shape)\n",
    "            # print(\"pred_box:\", pred_box.shape)\n",
    "            # print(\"grd_lbl:\", grd_lbl.shape)\n",
    "            # print(\"pred_lbl:\", pred_lbl.shape)\n",
    "            grd_box = grd_box.transpose(1, 2).contiguous()\n",
    "            loss = loss_fn(pred_box, pred_lbl, grd_box, grd_lbl)\n",
    "\n",
    "            progress_bar.set_description(\"Epoch: {}. Loss: {:.5f}\".format(epoch + 1, loss.item()))\n",
    "            writer.add_scalar(\"Train Loss\", loss.item(), epoch * num_iter_per_epoch + i)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            total += cnt\n",
    "            sum_loss += loss.item()\n",
    "            _, pred = torch.max(pred_lbl, 1)\n",
    "            corrects += torch.sum(pred.eq(grd_lbl)).item()\n",
    "        train_loss = sum_loss/total\n",
    "        train_acc = corrects /total\n",
    "        evaluate(model, test_loader, epoch, writer, encoder, nms_threshold)\n",
    "        \n",
    "        # history\n",
    "        train_loss_l.append(train_loss)\n",
    "        train_acc_l.append(train_acc)\n",
    "        print(\"Epoch: {}, Train Loss: {}\".format(epoch, round(train_loss, 3)))\n",
    "        \n",
    "    return modellib, train_loss_l, train_acc_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(modellib, test_loader, epoch, writer, encoder, nms_threshold):\n",
    "    modellib.eval()\n",
    "    detections = []\n",
    "    cat_ids = test_loader.dataset.coco.getCatIds()\n",
    "    progress_bar = tqdm(test_loader)\n",
    "    count = 0\n",
    "    for nbatch, (img, img_id, img_size, grd_box, grd_lbl) in enumerate(progress_bar):\n",
    "        # print(\"Parsing batch: {}/{}\".format(nbatch, len(test_loader)), end=\"\\r\")\n",
    "        progress_bar.set_description(\"Validation : {}\".format(nbatch))\n",
    "        img = img.cuda()\n",
    "        with torch.no_grad():\n",
    "            # Get predictions\n",
    "            pred_box, pred_lbl = modellib(img)\n",
    "            pred_box, pred_lbl = pred_box.float(), pred_lbl.float()\n",
    "            \n",
    "            # print(\"grd_box:\", grd_box.shape)\n",
    "            # print(\"pred_box:\", pred_box.shape)\n",
    "            # print(\"grd_lbl:\", grd_lbl.shape)\n",
    "            # print(\"pred_lbl:\", pred_lbl.shape)       \n",
    "        \n",
    "            for idx in range(pred_box.shape[0]):\n",
    "                pred_box_i = pred_box[idx, :, :].unsqueeze(0)\n",
    "                pred_lbl_i = pred_lbl[idx, :, :].unsqueeze(0)\n",
    "                try:\n",
    "                    result = encoder.decode_batch(pred_box_i, pred_lbl_i, nms_threshold, 200)[0]\n",
    "                except:\n",
    "                    print(\"No object detected in idx: {}\".format(idx))\n",
    "                    continue\n",
    "\n",
    "                height, width = img_size[idx]\n",
    "                loc, label, prob = [r.cpu().numpy() for r in result]\n",
    "                for loc_, label_, prob_ in zip(loc, label, prob):\n",
    "                    detections.append([img_id[idx], loc_[0] * width, loc_[1] * height, (loc_[2] - loc_[0]) * width,\n",
    "                                       (loc_[3] - loc_[1]) * height, prob_,\n",
    "                                       cat_ids[label_ - 1]])\n",
    "        count = count + 1\n",
    "\n",
    "    detections = np.array(detections, dtype=np.float32)\n",
    "    coco_eval = COCOeval(test_loader.dataset.coco, test_loader.dataset.coco.loadRes(detections), iouType=\"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    checkpoint = {\"epoch\": epoch, \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(), \n",
    "                \"scheduler\": scheduler.state_dict()}\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "    writer.add_scalar(\"Test mAP\", coco_eval.stats[0], epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(123)\n",
    "batch_size = 1\n",
    "num_workers = 4\n",
    "log_dir = \"logs\"\n",
    "lr = 2.6e-3\n",
    "epochs = 10\n",
    "momentum = 0.9\n",
    "nms_threshold = 0.5\n",
    "weight_decay = 0.0005\n",
    "multi_step = [43, 54]\n",
    "data_path = \"data/vehicles\"\n",
    "save_folder = \"trained_models\"\n",
    "date_time = datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "   \n",
    "log_path = os.path.join(log_dir, date_time)\n",
    "save_path = os.path.join(log_path, save_folder)\n",
    "make_dirs(save_path)\n",
    "checkpoint_path = os.path.join(save_path, \"model_ssd.pth\")\n",
    "\n",
    "train_params = {\"batch_size\": batch_size,  \"shuffle\": True,\n",
    "                \"drop_last\": False, \"num_workers\": num_workers,\n",
    "                \"collate_fn\": collate_fn}\n",
    "\n",
    "test_params = {\"batch_size\": batch_size, \"shuffle\": False,\n",
    "                \"drop_last\": False, \"num_workers\": num_workers,\n",
    "                \"collate_fn\": collate_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyothir-dr/miniconda3/envs/detect/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "dboxes = BoxesGen()\n",
    "encoder = Encoder(dboxes)\n",
    "\n",
    "model = SSD(num_classes=4).to(device)\n",
    "    \n",
    "train_set = ObjectDataset(data_path, \"train\", SSDAugmentation(dboxes, (300, 300), val=False))\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_set = ObjectDataset(data_path, \"val\", SSDAugmentation(dboxes, (300, 300), val=True))\n",
    "test_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "# update lr\n",
    "lr = lr * (batch_size / 32)\n",
    "\n",
    "loss_fn = Loss(dboxes).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum,\n",
    "                            weight_decay=weight_decay, nesterov=True)\n",
    "\n",
    "scheduler = MultiStepLR(optimizer = optimizer, milestones = multi_step, gamma=0.1)\n",
    "# model.cuda()\n",
    "# loss_fn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    first_epoch = checkpoint[\"epoch\"] + 1\n",
    "    # model.module.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "else:\n",
    "    first_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 20:40:07.642938: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996e240da27d4529811722382fc81ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5924beadce5430792e8c0ef35d953ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(68800, 7)\n",
      "0/68800\n",
      "DONE (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.52s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
      "Epoch: 0, Train Loss: 9.824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9319cb134af44238378fdcf8d605d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb#ch0000009?line=0'>1</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb#ch0000009?line=1'>2</a>\u001b[0m modellib, train_loss_l, train_acc_l \u001b[39m=\u001b[39m train_epoc(model, train_loader, epochs, writer, loss_fn, optimizer, scheduler)\n",
      "\u001b[1;32m/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_epoc\u001b[0;34m(modellib, train_loader, epochs, writer, loss_fn, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb#ch0000009?line=25'>26</a>\u001b[0m progress_bar\u001b[39m.\u001b[39mset_description(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Loss: \u001b[39m\u001b[39m{:.5f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb#ch0000009?line=26'>27</a>\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m.\u001b[39mitem(), epoch \u001b[39m*\u001b[39m num_iter_per_epoch \u001b[39m+\u001b[39m i)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb#ch0000009?line=28'>29</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb#ch0000009?line=29'>30</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/BA5672185671D59B/RCNN/object_detection/ssd_train.ipynb#ch0000009?line=30'>31</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/detect/lib/python3.8/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/detect/lib/python3.8/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    146\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    147\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "modellib, train_loss_l, train_acc_l = train_epoc(model, train_loader, epochs, writer, loss_fn, optimizer, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('detect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cbf2d2672eb1d51db66da973b7f534e15d3112a510a2d9edb972ac6185763d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
