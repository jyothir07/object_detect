{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "import os\n",
    "from utils import make_dirs, BoxesGen, Encoder, SSDAugmentation\n",
    "from model import SSD\n",
    "from dataloader import collate_fn\n",
    "from  PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"background\", \"bicycle\", \"car\", \"motorcycle\", \"bus\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSD()\n",
    "classes = [\"background\", \"bicycle\", \"car\", \"motorcycle\", \"bus\"] \n",
    "colors = [None, (164, 80, 133), (39, 129, 113), (83, 122, 114), (99, 81, 172)]\n",
    "batch_size = 1\n",
    "num_workers = 4\n",
    "nms_threshold = 0.5\n",
    "cls_threshold = 0.5\n",
    "pretrained_model = \"\"\n",
    "output_path = \"output\"\n",
    "input_path = \"/mnt/BA5672185671D59B/RCNN/object_detection_old/data/objects/test\"\n",
    "result_df = pd.DataFrame({}, columns=['filename', 'class', 'id', 'coordinates'])\n",
    "\n",
    "checkpoint = torch.load(pretrained_model)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "dboxes = BoxesGen()\n",
    "encoder = Encoder(dboxes)\n",
    "transformer = SSDAugmentation(dboxes, (300, 300), val=True)\n",
    "data_path = \"\"\n",
    "\n",
    "test_params = {\"batch_size\": batch_size, \"shuffle\": False,\n",
    "                \"drop_last\": False, \"num_workers\": num_workers,\n",
    "                \"collate_fn\": collate_fn}\n",
    "#     test_set = CocoDataset(opt.data_path, 2017, \"val\", SSDTransformer(dboxes, (300, 300), val=True))\n",
    "import shutil\n",
    "if os.path.isdir(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "make_dirs(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/mnt/BA5672185671D59B/RCNN/object_detection_old/data/objects/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_imgs(loc, label, pred_score, output_path, output_img):\n",
    "    if len(loc) > 0:\n",
    "        loc[:, 0::2] *= width\n",
    "        loc[:, 1::2] *= height\n",
    "        loc = loc.astype(np.int32)\n",
    "        for box, lb, pr in zip(loc, label, pred_score):\n",
    "            category = classes[lb]\n",
    "            color = colors[lb]\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            filename_l.append(image)\n",
    "            class_l.append(category)\n",
    "            id_l.append(lb)\n",
    "            coord_l.append([xmin, ymin, xmax, ymax])\n",
    "            cv2.rectangle(output_img, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            text_size = cv2.getTextSize(category + \" : %.2f\" % pr, cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "            cv2.rectangle(output_img, (xmin, ymin), (xmin + text_size[0] + 3, ymin + text_size[1] + 4), color, -1)\n",
    "            cv2.putText(output_img, category + \" : %.2f\" % pr,\n",
    "                        (xmin, ymin + text_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "        if output is None:\n",
    "            output = \"{}_res.jpg\".format(output_path[:-4])\n",
    "        else:\n",
    "            output = output\n",
    "        cv2.imwrite(output, output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_l = []\n",
    "class_l = []\n",
    "id_l = []\n",
    "coord_l = []\n",
    "list_images = os.listdir(input_path)\n",
    "for image in list_images:\n",
    "    with torch.no_grad():\n",
    "        output_img = Image.open(os.path.join(input_path, image)).convert(\"RGB\")\n",
    "        # print(os.path.join(input_path, image))\n",
    "        img = output_img.copy()\n",
    "        height, width = img.size[0], img.size[1]\n",
    "        img, _, _, _ = transformer(img, None, torch.zeros(1,4), torch.zeros(1))\n",
    "        img = img.unsqueeze(dim=0)\n",
    "        img = img.to(device)\n",
    "        pred_box, pred_lbl = model(img)\n",
    "        result = encoder.decode_batch(pred_box, pred_lbl, nms_threshold, 20)[0]\n",
    "        loc, label, pred_score = [r.cpu().numpy() for r in result]\n",
    "        best = np.argwhere(pred_score > cls_threshold).squeeze(axis=1)\n",
    "        loc, label, pred_score = loc[best], label[best], pred_score[best]\n",
    "        annotate_imgs(loc, label, pred_score, output_img, output_path)\n",
    "        \n",
    "result_df['filename'] = filename_l\n",
    "result_df['class'] = class_l\n",
    "result_df['id'] = id_l\n",
    "result_df['coordinates'] = coord_l\n",
    "result_df.to_csv('result_submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('detect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cbf2d2672eb1d51db66da973b7f534e15d3112a510a2d9edb972ac6185763d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
